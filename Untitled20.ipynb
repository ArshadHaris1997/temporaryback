{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9158a7bb-627d-4191-8741-92fbe8b66838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries for entire process\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2640a2b5-83d2-4584-9d79-50e615c647f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset function\n",
    "def preprocess_data(data):\n",
    "    # Handle missing values\n",
    "    data['Date_of_Last_Visit'] = pd.to_datetime(data['Date_of_Last_Visit'], errors='coerce')\n",
    "    data['Date_of_Surgery'] = pd.to_datetime(data['Date_of_Surgery'], errors='coerce')\n",
    "    data['Time_Since_Surgery'] = (data['Date_of_Last_Visit'] - data['Date_of_Surgery']).dt.days.fillna(0)\n",
    "    data['Patient_Status'] = data['Patient_Status'].fillna('Unknown')\n",
    "\n",
    "    # Encode categorical variables\n",
    "    categorical_columns = ['Gender', 'Tumour_Stage', 'Histology', 'ER status', 'PR status', 'HER2 status', 'Surgery_type', 'Patient_Status']\n",
    "    for col in categorical_columns:\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    data.drop(['Patient_ID', 'Date_of_Surgery', 'Date_of_Last_Visit'], axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f35ca8e-248d-4b87-b2c3-7909844bcfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def perform_classification(X, y):\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define hyperparameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Perform Grid Search for best hyperparameters\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_clf = grid_search.best_estimator_  # Retrieve the best model\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "    # Train and predict using the fine-tuned model\n",
    "    best_clf.fit(X_train, y_train)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "    y_proba = best_clf.predict_proba(X_test)\n",
    "\n",
    "    # Evaluate Classification Model (same as before)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Compute ROC AUC score\n",
    "    if len(set(y)) > 2:  # Multi-class case\n",
    "        y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
    "        roc_auc = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr', average='weighted')\n",
    "    else:  # Binary case\n",
    "        roc_auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "\n",
    "    print(\"Classification Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "\n",
    "    # Confusion Matrix and ROC Curve plotting remain the same as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a54c51d-7e4b-4034-8892-0c1f60961348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(X):\n",
    "    # Test different numbers of clusters to find the best one\n",
    "    silhouette_scores = []\n",
    "    cluster_range = range(2, 10)  # Evaluate from 2 to 9 clusters\n",
    "    \n",
    "    for n_clusters in cluster_range:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        clusters = kmeans.fit_predict(X)\n",
    "        sil_score = silhouette_score(X, clusters)\n",
    "        silhouette_scores.append(sil_score)\n",
    "        print(f\"Silhouette Score for {n_clusters} clusters: {sil_score:.2f}\")\n",
    "\n",
    "    # Select the best number of clusters based on the silhouette score\n",
    "    optimal_clusters = cluster_range[np.argmax(silhouette_scores)]\n",
    "    print(f\"Optimal number of clusters: {optimal_clusters}\")\n",
    "    \n",
    "    # Apply KMeans with the optimal number of clusters\n",
    "    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Visualize Clusters using PCA\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
    "    plt.title(f'K-Means Clustering with {optimal_clusters} Clusters (PCA Reduced)')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ece09794-8095-4cbe-bf54-b01e56065c88",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Time_Since_Surgery'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Time_Since_Surgery'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Advanced missing value handling\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Since_Surgery\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Since_Surgery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Since_Surgery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Feature engineering\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mER_PR_status_combined\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mER status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPR status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Time_Since_Surgery'"
     ]
    }
   ],
   "source": [
    "# Advanced missing value handling\n",
    "data['Time_Since_Surgery'] = data['Time_Since_Surgery'].fillna(data['Time_Since_Surgery'].median())\n",
    "\n",
    "# Feature engineering\n",
    "data['ER_PR_status_combined'] = data['ER status'].astype(str) + \"_\" + data['PR status'].astype(str)\n",
    "\n",
    "# Experiment with OneHotEncoder for better interpretability of categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_columns = encoder.fit_transform(data[categorical_columns])\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "data = pd.concat([data.drop(categorical_columns, axis=1), encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f337ed-4017-48a9-ba46-64eb0d8ad103",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Load and preprocess the data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbreast_cancer_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     data \u001b[38;5;241m=\u001b[39m preprocess_data(data)\n\u001b[0;32m      6\u001b[0m     X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient_Status\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m     y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient_Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_data' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess the data\n",
    "    data = pd.read_csv('breast_cancer_data.csv')\n",
    "    data = preprocess_data(data)\n",
    "\n",
    "    X = data.drop('Patient_Status', axis=1)\n",
    "    y = data['Patient_Status']\n",
    "\n",
    "    # Scale data for clustering\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Perform Classification with Fine-Tuning\n",
    "    print(\"=== Classification Task (Fine-Tuned) ===\")\n",
    "    perform_classification(X_scaled, y)\n",
    "\n",
    "    # Perform Clustering with Fine-Tuning\n",
    "    print(\"\\n=== Clustering Task (Fine-Tuned) ===\")\n",
    "    perform_clustering(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39acb065-0abe-4c63-878c-dafe5634f0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
